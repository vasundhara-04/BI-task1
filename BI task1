# Importing necessary libraries
import pandas as pd
import nltk
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Download NLTK resources
nltk.download('stopwords')
nltk.download('punkt')

# Load the dataset
data = pd.read_csv('sms_spam.csv')

# Data preprocessing
data['text'] = data['text'].str.lower()  # Convert text to lowercase
data['text'] = data['text'].str.replace('[^\w\s]', '')  # Remove punctuations
data['text'] = data['text'].apply(nltk.word_tokenize)  # Tokenize text

# Feature extraction
vectorizer = CountVectorizer(analyzer='word', stop_words='english')
X = vectorizer.fit_transform(data['text'].apply(' '.join))
y = data['label']

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model training
model = MultinomialNB()
model.fit(X_train, y_train)

# Model evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print("\nClassification Report:")
print(classification_report(y_test, y_pred))




